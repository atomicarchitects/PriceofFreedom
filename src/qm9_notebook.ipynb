{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from absl import logging\n",
    "import optax\n",
    "import tqdm\n",
    "import jax\n",
    "import jraph\n",
    "import jax.numpy as jnp\n",
    "import e3nn_jax as e3nn\n",
    "import flax.linen as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import lovelyplots\n",
    "plt.style.use('ipynb')\n",
    "\n",
    "logging.set_verbosity(logging.DEBUG)\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.data.qm9 import QM9Dataset\n",
    "from src import tensor_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Target property mu: Dipole moment (D)\n",
      "/Users/ameyad/Documents/vector-spherical-harmonics/.venv/lib/python3.11/site-packages/torch_geometric/data/dataset.py:239: UserWarning: The `pre_transform` argument differs from the one used in the pre-processed version of this dataset. If you want to make use of another pre-processing technique, pass `force_reload=True` explicitly to reload the dataset.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ds = QM9Dataset(root='../data', target_property='mu', cutoff=5.0, add_self_edges=True, splits={\n",
    "    'train': 110000,\n",
    "    'val': 10000,\n",
    "}, seed=0)\n",
    "datasets = ds.get_datasets(batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Creating train dataset.\n",
      "INFO:absl:Split train: Padding computed as {'n_node': 1152, 'n_edge': 2432, 'n_graph': 33}\n"
     ]
    }
   ],
   "source": [
    "# Models\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    output_dims: int\n",
    "    hidden_dims: int = 32\n",
    "    num_layers: int = 2\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n",
    "        for _ in range(self.num_layers - 1):\n",
    "            x = nn.Dense(features=self.hidden_dims)(x)\n",
    "            x = nn.LayerNorm()(x)\n",
    "            x = nn.silu(x)\n",
    "        x = nn.Dense(features=self.output_dims)(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SimpleNetwork(nn.Module):\n",
    "\n",
    "    sh_lmax: int\n",
    "    lmax: int\n",
    "    init_node_features: int\n",
    "    max_atomic_number: int\n",
    "    num_hops: int\n",
    "    output_dims: int\n",
    "    tensor_product_fn: Callable[[], nn.Module]\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, graphs: jraph.GraphsTuple) -> jnp.ndarray:\n",
    "        # Node features are initially the atomic numbers embedded.\n",
    "        node_features = graphs.nodes['numbers']\n",
    "        node_features = nn.Embed(num_embeddings=self.max_atomic_number, features=self.init_node_features)(node_features)\n",
    "        node_features = e3nn.IrrepsArray(f\"{self.init_node_features}x0e\", node_features)\n",
    "        \n",
    "        # Precompute the spherical harmonics of the relative vectors.\n",
    "        relative_vectors = graphs.edges[\"relative_vectors\"]\n",
    "        relative_vectors_sh = e3nn.spherical_harmonics(e3nn.s2_irreps(lmax=self.sh_lmax), relative_vectors, normalize=True,\n",
    "                                                       normalization='norm')\n",
    "        relative_vectors_norm = jnp.linalg.norm(relative_vectors, axis=-1, keepdims=True)\n",
    "        \n",
    "        # print(\"relative_vectors_sh\", e3nn.norm(relative_vectors_sh))\n",
    "        # print(\"node_features\", e3nn.norm(node_features))\n",
    "\n",
    "        for _ in range(self.num_hops):\n",
    "            # Tensor product of the relative vectors and the neighbouring node features.\n",
    "            node_features_broadcasted = node_features[graphs.senders]\n",
    "            tp = self.tensor_product_fn()(\n",
    "                relative_vectors_sh, node_features_broadcasted\n",
    "            )\n",
    "            tp = tp.filter(lmax=self.lmax)\n",
    "\n",
    "            # Apply a linear transformation to the tensor product.\n",
    "            tp = e3nn.flax.Linear(tp.irreps)(tp)\n",
    "\n",
    "            # Simply multiply each irrep by a learned scalar.\n",
    "            scalars = MLP(output_dims=tp.irreps.num_irreps)(relative_vectors_norm)\n",
    "            scalars = e3nn.IrrepsArray(f\"{scalars.shape[-1]}x0e\", scalars)\n",
    "            node_features_broadcasted = jax.vmap(lambda sc, feat: sc * feat)(scalars, tp)\n",
    "\n",
    "            # Aggregate the node features back.\n",
    "            node_features = e3nn.scatter_mean(node_features_broadcasted, dst=graphs.receivers, output_size=node_features.shape[0])\n",
    "\n",
    "        # Global readout.\n",
    "        graph_globals = e3nn.scatter_mean(node_features.filter(\"0e\"), nel=graphs.n_node)\n",
    "        return MLP(output_dims=self.output_dims)(graph_globals.array)\n",
    "\n",
    "import functools\n",
    "model = SimpleNetwork(\n",
    "    sh_lmax=2,\n",
    "    lmax=2,\n",
    "    init_node_features=16,\n",
    "    max_atomic_number=12,\n",
    "    num_hops=3,\n",
    "    output_dims=1,\n",
    "    tensor_product_fn=functools.partial(\n",
    "        tensor_products.TensorProductNaive,\n",
    "    )\n",
    ")\n",
    "params = model.init(jax.random.PRNGKey(0), graphs=next(datasets['train']))\n",
    "\n",
    "# Optimizer\n",
    "tx = optax.adam(learning_rate=0.01)\n",
    "opt_state = tx.init(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(params, graphs):\n",
    "    preds = model.apply(params, graphs)\n",
    "    labels = graphs.globals\n",
    "    assert preds.shape == labels.shape, (preds.shape, labels.shape)\n",
    "    loss = (preds - labels) ** 2\n",
    "    loss = jnp.mean(loss)\n",
    "    return loss, preds\n",
    "\n",
    "@jax.jit\n",
    "def update_fn(params, opt_state, graphs):\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, preds), grads = grad_fn(params, graphs)\n",
    "\n",
    "    updates, opt_state = tx.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state, loss, preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "losses = []\n",
    "steps = []\n",
    "num_steps = 100\n",
    "print(\"Training...\", flush=True)\n",
    "with tqdm.tqdm(range(num_steps)) as bar:\n",
    "    for step in bar:\n",
    "        graphs = next(datasets['train'])\n",
    "        params, opt_state, loss, preds = update_fn(params, opt_state, graphs)\n",
    "        \n",
    "        bar.set_postfix(loss=f\"{loss:.2f}\")\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            losses.append(loss)\n",
    "            steps.append(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(steps, losses)\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
