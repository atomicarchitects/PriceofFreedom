{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict, Any\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import e3nn_jax as e3nn\n",
    "import optax\n",
    "import chex\n",
    "from clu import parameter_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tetris_datasets(rng: chex.PRNGKey):\n",
    "    positions = jnp.asarray(\n",
    "        [\n",
    "            [(0, 0, 0), (0, 0, 1), (1, 0, 0), (1, 1, 0)],  # chiral_shape_1\n",
    "            [(0, 0, 0), (0, 0, 1), (1, 0, 0), (1, -1, 0)],  # chiral_shape_2\n",
    "            [(0, 0, 0), (1, 0, 0), (0, 1, 0), (1, 1, 0)],  # square\n",
    "            [(0, 0, 0), (0, 0, 1), (0, 0, 2), (0, 0, 3)],  # line\n",
    "            [(0, 0, 0), (0, 0, 1), (0, 1, 0), (1, 0, 0)],  # corner\n",
    "            [(0, 0, 0), (0, 0, 1), (0, 0, 2), (0, 1, 0)],  # L\n",
    "            [(0, 0, 0), (0, 0, 1), (0, 0, 2), (0, 1, 1)],  # T\n",
    "            [(0, 0, 0), (1, 0, 0), (1, 1, 0), (2, 1, 0)],  # zigzag\n",
    "        ],\n",
    "        dtype=jnp.float32,\n",
    "    )\n",
    "    positions = e3nn.IrrepsArray(\"1o\", positions)\n",
    "\n",
    "    # Since chiral shapes are the mirror of one another we need an *odd* scalar to distinguish them\n",
    "    labels = jnp.asarray(\n",
    "        [\n",
    "            [-1, 0, 0, 0, 0, 0, 0],  # chiral_shape_1\n",
    "            [1, 0, 0, 0, 0, 0, 0],  # chiral_shape_2\n",
    "            [0, 1, 0, 0, 0, 0, 0],  # square\n",
    "            [0, 0, 1, 0, 0, 0, 0],  # line\n",
    "            [0, 0, 0, 1, 0, 0, 0],  # corner\n",
    "            [0, 0, 0, 0, 1, 0, 0],  # L\n",
    "            [0, 0, 0, 0, 0, 1, 0],  # T\n",
    "            [0, 0, 0, 0, 0, 0, 1],  # zigzag\n",
    "        ],\n",
    "        dtype=jnp.int32,\n",
    "    )\n",
    "    labels = e3nn.IrrepsArray(\"0o + 6x0e\", labels)\n",
    "\n",
    "    while True:\n",
    "        # Apply a random rotation to the positions.\n",
    "        rotation_rng, rng = jax.random.split(rng)\n",
    "        random_rotations = e3nn.rand_matrix(rotation_rng, shape=(positions.shape[0],))\n",
    "        positions = jax.vmap(lambda pos, rot: pos.transform_by_matrix(rot))(\n",
    "            positions, random_rotations\n",
    "        )\n",
    "\n",
    "        # Apply a random translation to the positions.\n",
    "        translation_rng, rng = jax.random.split(rng)\n",
    "        random_translations = e3nn.normal(\n",
    "            \"1o\", translation_rng, leading_shape=(positions.shape[0],)\n",
    "        )\n",
    "        positions = positions + random_translations[:, None, :]\n",
    "\n",
    "        yield {\n",
    "            \"positions\": positions,\n",
    "            \"labels\": labels,\n",
    "        }\n",
    "\n",
    "\n",
    "rng = jax.random.PRNGKey(0)\n",
    "dataset = get_tetris_datasets(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNLayer(hk.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        radial_embedding_dims: int,\n",
    "        radial_embedding_layers: int,\n",
    "        output_lmax: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.radial_embedding_dims = radial_embedding_dims\n",
    "        self.radial_embedding_layers = radial_embedding_layers\n",
    "        self.output_lmax = output_lmax\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        node_features: e3nn.IrrepsArray,\n",
    "        distances: jnp.ndarray,\n",
    "        relative_positions_embedded: e3nn.IrrepsArray,\n",
    "        neighbor_features: e3nn.IrrepsArray,\n",
    "    ) -> e3nn.IrrepsArray:\n",
    "        def convolve_with_neighbours(\n",
    "            distances, relative_positions_embedded, neighbor_features\n",
    "        ):\n",
    "            product = e3nn.tensor_product(\n",
    "                relative_positions_embedded, neighbor_features\n",
    "            )\n",
    "            radial_mlp = e3nn.haiku.MultiLayerPerceptron(\n",
    "                [self.radial_embedding_dims] * (self.radial_embedding_layers - 1)\n",
    "                + [product.irreps.num_irreps],\n",
    "                act=jax.nn.swish,\n",
    "            )\n",
    "            radial = radial_mlp(distances)\n",
    "            return radial * product\n",
    "\n",
    "        convolved_features = hk.vmap(convolve_with_neighbours, split_rng=False)(\n",
    "            distances, relative_positions_embedded, neighbor_features\n",
    "        )\n",
    "        convolved_features = e3nn.mean(convolved_features, axis=-2)\n",
    "        node_features = e3nn.concatenate([node_features, convolved_features])\n",
    "        node_features = node_features.filter(lmax=self.output_lmax)\n",
    "        node_features = e3nn.haiku.Linear(\n",
    "            node_features.irreps + f\"{node_features.irreps.num_irreps}x0e\"\n",
    "        )(node_features)\n",
    "        node_features = e3nn.gate(node_features)\n",
    "        node_features = node_features.regroup()\n",
    "        return node_features\n",
    "\n",
    "\n",
    "class GNN(hk.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers: int,\n",
    "        lmax: int,\n",
    "        initial_embedding_dims: int,\n",
    "        radial_embedding_dims: int,\n",
    "        radial_embedding_layers: int,\n",
    "        hidden_lmax: int,\n",
    "        output_irreps: e3nn.Irreps,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.lmax = lmax\n",
    "        self.num_layers = num_layers\n",
    "        self.radial_embedding_dims = radial_embedding_dims\n",
    "        self.radial_embedding_layers = radial_embedding_layers\n",
    "        self.initial_embedding_dims = initial_embedding_dims\n",
    "        self.hidden_lmax = hidden_lmax\n",
    "        self.output_irreps = output_irreps\n",
    "\n",
    "    def __call__(self, positions: e3nn.IrrepsArray) -> e3nn.IrrepsArray:\n",
    "        num_graphs, num_nodes, _ = positions.shape\n",
    "        assert positions.shape == (num_graphs, num_nodes, 3)\n",
    "        relative_positions = jax.vmap(lambda pos: pos[None, :, :] - pos[:, None, :])(\n",
    "            positions\n",
    "        )\n",
    "        assert relative_positions.shape == (num_graphs, num_nodes, num_nodes, 3)\n",
    "\n",
    "        distances = e3nn.norm(relative_positions)\n",
    "        assert distances.shape == (num_graphs, num_nodes, num_nodes, 1), distances.shape\n",
    "\n",
    "        relative_positions_embedded = e3nn.spherical_harmonics(\n",
    "            e3nn.s2_irreps(self.lmax), relative_positions, normalize=True\n",
    "        )\n",
    "        assert relative_positions_embedded.shape == (\n",
    "            num_graphs,\n",
    "            num_nodes,\n",
    "            num_nodes,\n",
    "            (self.lmax + 1) ** 2,\n",
    "        )\n",
    "\n",
    "        node_features = e3nn.ones(\n",
    "            f\"{self.initial_embedding_dims}x0e\", leading_shape=(num_graphs, num_nodes)\n",
    "        )\n",
    "        assert node_features.irreps.is_scalar()\n",
    "        assert node_features.shape == (\n",
    "            num_graphs,\n",
    "            num_nodes,\n",
    "            self.initial_embedding_dims,\n",
    "        )\n",
    "\n",
    "        for _ in range(self.num_layers):\n",
    "            layer = GNNLayer(\n",
    "                self.radial_embedding_dims,\n",
    "                self.radial_embedding_layers,\n",
    "                self.hidden_lmax,\n",
    "            )\n",
    "            layer = hk.vmap(\n",
    "                layer, split_rng=False, in_axes=(0, 0, 0, None)\n",
    "            )  # node axis\n",
    "            layer = hk.vmap(layer, split_rng=False)  # graph axis\n",
    "            print(\"before\", node_features.irreps)\n",
    "\n",
    "            node_features = layer(\n",
    "                node_features, distances, relative_positions_embedded, node_features\n",
    "            )\n",
    "            print(\"after\", node_features.irreps)\n",
    "\n",
    "        global_features = e3nn.mean(node_features, axis=-2)\n",
    "        global_features = e3nn.haiku.Linear(self.output_irreps, force_irreps_out=True)(\n",
    "            global_features\n",
    "        )\n",
    "        # global_features = e3nn.scalar_activation(global_features)\n",
    "        return global_features, node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "@hk.without_apply_rng\n",
    "@hk.transform\n",
    "def model(\n",
    "    data: Dict[str, e3nn.IrrepsArray]\n",
    ") -> Tuple[e3nn.IrrepsArray, e3nn.IrrepsArray]:\n",
    "    gnn = GNN(\n",
    "        num_layers=3,\n",
    "        lmax=2,\n",
    "        radial_embedding_dims=5,\n",
    "        radial_embedding_layers=2,\n",
    "        initial_embedding_dims=2,\n",
    "        hidden_lmax=2,\n",
    "        output_irreps=\"0o + 6x0e\",\n",
    "    )\n",
    "    return gnn(data[\"positions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before 2x0e\n",
      "after 8x0e+2x1o+2x2e\n",
      "before 8x0e+2x1o+2x2e\n",
      "after 40x0e+16x1o+4x1e+16x2e+4x2o\n",
      "before 40x0e+16x1o+4x1e+16x2e+4x2o\n",
      "after 232x0e+8x0o+112x1o+48x1e+112x2e+48x2o\n",
      "+---------------------------------------------------+------------+--------+----------+-------+\n",
      "| Name                                              | Shape      | Size   | Mean     | Std   |\n",
      "+---------------------------------------------------+------------+--------+----------+-------+\n",
      "| gnn/gnn_layer/linear/w[0,0] 4x0e,4x0e             | (4, 4)     | 16     | 0.0553   | 0.539 |\n",
      "| gnn/gnn_layer/linear/w[0,3] 4x0e,8x0e             | (4, 8)     | 32     | -0.0265  | 1.27  |\n",
      "| gnn/gnn_layer/linear/w[1,1] 2x1o,2x1o             | (2, 2)     | 4      | 0.213    | 0.898 |\n",
      "| gnn/gnn_layer/linear/w[2,2] 2x2e,2x2e             | (2, 2)     | 4      | -0.577   | 0.631 |\n",
      "| gnn/gnn_layer/multi_layer_perceptron/linear_0/w   | (1, 5)     | 5      | -0.253   | 1.58  |\n",
      "| gnn/gnn_layer/multi_layer_perceptron/linear_1/w   | (5, 6)     | 30     | -0.182   | 0.892 |\n",
      "| gnn/gnn_layer_1/linear/w[0,0] 20x0e,8x0e          | (20, 8)    | 160    | -0.0929  | 1.04  |\n",
      "| gnn/gnn_layer_1/linear/w[0,3] 20x0e,12x0e         | (20, 12)   | 240    | 0.000105 | 1.03  |\n",
      "| gnn/gnn_layer_1/linear/w[0,8] 20x0e,60x0e         | (20, 60)   | 1,200  | 0.0381   | 0.99  |\n",
      "| gnn/gnn_layer_1/linear/w[1,1] 16x1o,2x1o          | (16, 2)    | 32     | -0.0323  | 1.06  |\n",
      "| gnn/gnn_layer_1/linear/w[1,4] 16x1o,14x1o         | (16, 14)   | 224    | -0.0547  | 1.0   |\n",
      "| gnn/gnn_layer_1/linear/w[2,5] 4x1e,4x1e           | (4, 4)     | 16     | -0.112   | 0.782 |\n",
      "| gnn/gnn_layer_1/linear/w[3,2] 16x2e,2x2e          | (16, 2)    | 32     | -0.183   | 0.83  |\n",
      "| gnn/gnn_layer_1/linear/w[3,6] 16x2e,14x2e         | (16, 14)   | 224    | 0.0177   | 1.03  |\n",
      "| gnn/gnn_layer_1/linear/w[4,7] 4x2o,4x2o           | (4, 4)     | 16     | 0.111    | 1.06  |\n",
      "| gnn/gnn_layer_1/multi_layer_perceptron/linear_0/w | (1, 5)     | 5      | 0.226    | 1.14  |\n",
      "| gnn/gnn_layer_1/multi_layer_perceptron/linear_1/w | (5, 56)    | 280    | -0.0743  | 0.987 |\n",
      "| gnn/gnn_layer_2/linear/w[0,0] 112x0e,40x0e        | (112, 40)  | 4,480  | -0.00245 | 1.0   |\n",
      "| gnn/gnn_layer_2/linear/w[0,11] 112x0e,440x0e      | (112, 440) | 49,280 | 0.00846  | 1.0   |\n",
      "| gnn/gnn_layer_2/linear/w[0,5] 112x0e,72x0e        | (112, 72)  | 8,064  | -0.00964 | 0.996 |\n",
      "| gnn/gnn_layer_2/linear/w[1,6] 8x0o,8x0o           | (8, 8)     | 64     | -0.209   | 0.785 |\n",
      "| gnn/gnn_layer_2/linear/w[2,1] 112x1o,16x1o        | (112, 16)  | 1,792  | -0.024   | 1.01  |\n",
      "| gnn/gnn_layer_2/linear/w[2,7] 112x1o,96x1o        | (112, 96)  | 10,752 | 0.00707  | 0.999 |\n",
      "| gnn/gnn_layer_2/linear/w[3,2] 48x1e,4x1e          | (48, 4)    | 192    | 0.00659  | 0.985 |\n",
      "| gnn/gnn_layer_2/linear/w[3,8] 48x1e,44x1e         | (48, 44)   | 2,112  | -0.0218  | 0.99  |\n",
      "| gnn/gnn_layer_2/linear/w[4,3] 112x2e,16x2e        | (112, 16)  | 1,792  | 0.036    | 0.98  |\n",
      "| gnn/gnn_layer_2/linear/w[4,9] 112x2e,96x2e        | (112, 96)  | 10,752 | 0.00763  | 1.0   |\n",
      "| gnn/gnn_layer_2/linear/w[5,10] 48x2o,44x2o        | (48, 44)   | 2,112  | 0.0486   | 1.01  |\n",
      "| gnn/gnn_layer_2/linear/w[5,4] 48x2o,4x2o          | (48, 4)    | 192    | 0.0905   | 1.05  |\n",
      "| gnn/gnn_layer_2/multi_layer_perceptron/linear_0/w | (1, 5)     | 5      | 0.864    | 0.778 |\n",
      "| gnn/gnn_layer_2/multi_layer_perceptron/linear_1/w | (5, 440)   | 2,200  | 0.0444   | 1.0   |\n",
      "| gnn/linear/w[0,1] 232x0e,6x0e                     | (232, 6)   | 1,392  | -0.022   | 1.01  |\n",
      "| gnn/linear/w[1,0] 8x0o,1x0o                       | (8, 1)     | 8      | -0.165   | 1.07  |\n",
      "+---------------------------------------------------+------------+--------+----------+-------+\n",
      "Total: 97,709\n",
      "before 2x0e\n",
      "after 8x0e+2x1o+2x2e\n",
      "before 8x0e+2x1o+2x2e\n",
      "after 40x0e+16x1o+4x1e+16x2e+4x2o\n",
      "before 40x0e+16x1o+4x1e+16x2e+4x2o\n",
      "after 232x0e+8x0o+112x1o+48x1e+112x2e+48x2o\n",
      "Step 0: loss=120.40560150146484\n",
      "Step 100: loss=0.8339544534683228\n",
      "Step 200: loss=0.6427541971206665\n",
      "Step 300: loss=0.5897654891014099\n",
      "Step 400: loss=0.5309669971466064\n",
      "Step 500: loss=0.313681036233902\n",
      "Step 600: loss=0.24152871966362\n",
      "Step 700: loss=0.20690123736858368\n",
      "Step 800: loss=0.1689862459897995\n",
      "Step 900: loss=0.1292683482170105\n",
      "Step 1000: loss=0.09134159982204437\n"
     ]
    }
   ],
   "source": [
    "def train_on_dataset(model, dataset, num_training_steps: int):\n",
    "\n",
    "    params = model.init(jax.random.PRNGKey(0), next(dataset))\n",
    "    print(parameter_overview.get_parameter_overview(params))\n",
    "\n",
    "    tx = optax.adam(1e-3)\n",
    "    opt_state = tx.init(params)\n",
    "    apply_fn = jax.jit(model.apply)\n",
    "\n",
    "    def loss_fn(params, data):\n",
    "        global_embedding, _ = apply_fn(params, data)\n",
    "        return e3nn.norm(\n",
    "            (global_embedding - data[\"labels\"]), squared=True, per_irrep=False\n",
    "        ).array.mean()\n",
    "\n",
    "    @jax.jit\n",
    "    def train_step(params, opt_state, data):\n",
    "        loss_value, grads = jax.value_and_grad(loss_fn)(params, data)\n",
    "        updates, opt_state = tx.update(grads, opt_state, params)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "        return params, opt_state, loss_value\n",
    "\n",
    "    for step, data in enumerate(dataset):\n",
    "        params, opt_state, loss_value = train_step(params, opt_state, data)\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step {step}: loss={loss_value}\")\n",
    "\n",
    "        if step > num_training_steps:\n",
    "            break\n",
    "\n",
    "    return params\n",
    "\n",
    "\n",
    "params = train_on_dataset(model, dataset, num_training_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before 2x0e\n",
      "after 8x0e+2x1o+2x2e\n",
      "before 8x0e+2x1o+2x2e\n",
      "after 40x0e+16x1o+4x1e+16x2e+4x2o\n",
      "before 40x0e+16x1o+4x1e+16x2e+4x2o\n",
      "after 232x0e+8x0o+112x1o+48x1e+112x2e+48x2o\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([[-1.        , -0.05      , -0.02      ,  0.07      , -0.        ,\n",
       "         0.12      , -0.        ],\n",
       "       [ 1.        , -0.05      , -0.02      ,  0.07      , -0.        ,\n",
       "         0.12      , -0.        ],\n",
       "       [ 0.        ,  0.78999996, -0.06      ,  0.16      , -0.03      ,\n",
       "         0.12      ,  0.05      ],\n",
       "       [ 0.        , -0.        ,  0.98999995,  0.        ,  0.        ,\n",
       "        -0.01      ,  0.01      ],\n",
       "       [ 0.        ,  0.22999999,  0.06      ,  0.82      ,  0.04      ,\n",
       "        -0.13      , -0.07      ],\n",
       "       [ 0.        , -0.05      ,  0.03      ,  0.08      ,  0.78      ,\n",
       "        -0.04      ,  0.26      ],\n",
       "       [ 0.        ,  0.07      ,  0.02      , -0.06      , -0.04      ,\n",
       "         0.74      ,  0.08      ],\n",
       "       [ 0.        ,  0.05      , -0.02      , -0.11      ,  0.29      ,\n",
       "         0.16      ,  0.61      ]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, _ = model.apply(params, next(dataset))\n",
    "preds.array.round(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
